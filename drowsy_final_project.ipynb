{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQNC_jZbWNq7"
      },
      "source": [
        "# Drowsiness Detection Final Project\n",
        "This colab contains the implementation of our final project, pulling our pre-processing and data augmentation code from Github, running our dataset through it, then applying another model, VideoSWIN, to produce the final results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCdY9y5zaI08"
      },
      "source": [
        "# Step 0: Project Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq1PJ7shXdh3"
      },
      "source": [
        "## Pulling the Github Repository\n",
        "To get Colab to access the Github repository, run the following code block:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8j0SHXuYejk",
        "outputId": "8113b052-313d-4978-9ba3-d4f1760ec236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-final-project'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 336 (delta 45), reused 57 (delta 23), pack-reused 257\u001b[K\n",
            "Receiving objects: 100% (336/336), 7.58 MiB | 27.12 MiB/s, done.\n",
            "Resolving deltas: 100% (197/197), done.\n"
          ]
        }
      ],
      "source": [
        "# Call code to load the repository into Colab's runtime.\n",
        "# Todo: see how Ethan coded his pre-processing step to run\n",
        "# so that it can also work in colab\n",
        "!git clone https://github.com/EtomicBomb/deep-learning-final-project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U02HWfTNfyIy",
        "outputId": "be6c2159-6070-4301-a663-2fbd1c03e535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No local changes to save\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!cd /content/deep-learning-final-project; git stash; git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIWtUCBsYtFE"
      },
      "source": [
        "## Pulling in the data from Google Drive\n",
        "\n",
        "WARNING: before running below, you must make a shortcut of the shared folder that includes the data. Follow the steps below:\n",
        "\n",
        "1. Have the `deep-learning-final-project` folder shared with you.\n",
        "2. Right-click the folder and click `Organize` then `Add Shortcut`. when choosing where, click `All Locations` then choose your `Drive`.\n",
        "3. Make sure not to rename the shortcut!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdVqIXKkYxW6",
        "outputId": "9a1fd9aa-b713-46ae-c37c-75a1302e2e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Gf9ekbZN3G"
      },
      "source": [
        "## Running Data Preprocessing on Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSY-3-7WZUbT",
        "outputId": "d9a48368-d0b3-4893-bc27-1c4742768deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VideoSwin'...\n",
            "remote: Enumerating objects: 840, done.\u001b[K\n",
            "remote: Counting objects: 100% (306/306), done.\u001b[K\n",
            "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
            "remote: Total 840 (delta 208), reused 221 (delta 146), pack-reused 534\u001b[K\n",
            "Receiving objects: 100% (840/840), 7.86 MiB | 38.16 MiB/s, done.\n",
            "Resolving deltas: 100% (490/490), done.\n",
            "/content/VideoSwin\n",
            "Branch 'tfkeras' set up to track remote branch 'tfkeras' from 'origin'.\n",
            "Switched to a new branch 'tfkeras'\n",
            "Obtaining file:///content/VideoSwin\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from videoswin==1.0.0) (4.8.0.76)\n",
            "Requirement already satisfied: tensorflow>=2.12 in /usr/local/lib/python3.10/dist-packages (from videoswin==1.0.0) (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.2->videoswin==1.0.0) (1.25.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.12->videoswin==1.0.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (3.2.2)\n",
            "Installing collected packages: videoswin\n",
            "  Running setup.py develop for videoswin\n",
            "Successfully installed videoswin-1.0.0\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.4.24)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting av\n",
            "  Downloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-12.0.0\n",
            "Collecting keras_cv\n",
            "  Downloading keras_cv-0.9.0-py3-none-any.whl (650 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_cv) (24.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_cv) (2023.12.25)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras_cv) (4.9.4)\n",
            "Collecting keras-core (from keras_cv)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (13.7.1)\n",
            "Collecting namex (from keras-core->keras_cv)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.1.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.5.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (6.4.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (4.11.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2024.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets->keras_cv) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.2)\n",
            "Installing collected packages: namex, keras-core, keras_cv\n",
            "Successfully installed keras-core-0.1.7 keras_cv-0.9.0 namex-0.0.8\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# fulfill requirements\n",
        "# !pip install -r requirements.txt\n",
        "!git clone https://github.com/innat/VideoSwin.git\n",
        "%cd VideoSwin\n",
        "!git checkout tfkeras\n",
        "!pip install -e  .\n",
        "!pip install scikit-image\n",
        "# dlib\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install av\n",
        "!pip install keras_cv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qshlhlWtp5OE",
        "outputId": "da47eb04-d85d-4a46-a49d-811ef4c11bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning-final-project/src\n"
          ]
        }
      ],
      "source": [
        "%cd /content/deep-learning-final-project/src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT1GdbGyv_0j",
        "outputId": "a2962486-ad7f-4682-9cba-de1ce380f8db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n",
            "running Scale...\n",
            "running Gray2RGB...\n",
            "running Scale...\n",
            "running Gray2RGB...\n",
            "running Scale...\n",
            "running Gray2RGB...\n",
            "running Scale...\n",
            "running Gray2RGB...\n",
            "running Scale...\n",
            "running Gray2RGB...\n"
          ]
        }
      ],
      "source": [
        "from main import get_data\n",
        "import tensorflow as tf\n",
        "\n",
        "validation_steps = 53\n",
        "\n",
        "with tf.device('/CPU:0'):\n",
        "    train_data = get_data(\n",
        "        mode='train',\n",
        "        extract_root='/content/drive/MyDrive/deep-learning-final-project/data-2024-03-25/extract/',\n",
        "        data_root='/content/deep-learning-final-project/data',\n",
        "        batch_size=10,\n",
        "        frame_count=32,\n",
        "    )\n",
        "    test_data = get_data(\n",
        "        mode='test',\n",
        "        extract_root='/content/drive/MyDrive/deep-learning-final-project/data-2024-03-25/extract/',\n",
        "        data_root='/content/deep-learning-final-project/data',\n",
        "        batch_size=10,\n",
        "        frame_count=32,\n",
        "        validation_steps=validation_steps,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZQQZWOSDYLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57444115-54d5-40b1-9791-c75df00716fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(2, 32, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(2, 32, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "print(train_data)\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17s605yFY3qA"
      },
      "source": [
        "## Pulling in VideoSWIN model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpn6MApiZD85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0952ef0b-764e-4a85-8f66-e57e94b1165b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VideoSwin\n"
          ]
        }
      ],
      "source": [
        "%cd /content/VideoSwin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjICPp0gBQh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f2bcad3-888f-4a1c-e768-5d1ef3c84d95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-06 04:11:25--  https://github.com/innat/VideoSwin/releases/download/v1.1/TFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/697696973/e6869381-0418-4489-bee3-99857237886b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240506%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240506T041125Z&X-Amz-Expires=300&X-Amz-Signature=48e6ea8781a585950eb3e86c42cd530708341df866ae1144638295f8b2940cce&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=697696973&response-content-disposition=attachment%3B%20filename%3DTFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-05-06 04:11:25--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/697696973/e6869381-0418-4489-bee3-99857237886b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240506%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240506T041125Z&X-Amz-Expires=300&X-Amz-Signature=48e6ea8781a585950eb3e86c42cd530708341df866ae1144638295f8b2940cce&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=697696973&response-content-disposition=attachment%3B%20filename%3DTFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 335787590 (320M) [application/octet-stream]\n",
            "Saving to: ‘TFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip’\n",
            "\n",
            "TFVideoSwinB_SSV2_K 100%[===================>] 320.23M  33.3MB/s    in 7.8s    \n",
            "\n",
            "2024-05-06 04:11:33 (41.1 MB/s) - ‘TFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip’ saved [335787590/335787590]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://github.com/innat/VideoSwin/releases/download/v1.1/TFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip'\n",
        "!unzip -q '/content/VideoSwin/TFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQddCOFbZj-U"
      },
      "source": [
        "## Establish Model Architecture + Loss Function, Call Function, Optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5IpQQkJZv_Q"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "import tensorflow.keras\n",
        "import keras\n",
        "\n",
        "# video_swin = load_model('/content/VideoSwin/videoswin_base_something_something_v2.weights.h5', compile=False)\n",
        "# video_swin = keras.layers.TFSMLayer(\n",
        "#     '/content/VideoSwin/TFVideoSwinB_SSV2_K400_P244_W1677_32x224',\n",
        "#     call_endpoint='serving_default',\n",
        "#     trainable=False,\n",
        "# )\n",
        "# policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "# tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "video_swin = load_model('/content/VideoSwin/TFVideoSwinB_SSV2_K400_P244_W1677_32x224', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import clone_model\n",
        "\n",
        "\n",
        "count = 0\n",
        "for layer in video_swin.layers:\n",
        "    if True:#count in [0, 5, 6, 8]:\n",
        "        layer.trainable = True\n",
        "        print(f\"{layer.name} set to trainable\")\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "    count += 1\n",
        "\n",
        "\n",
        "# print(f\"\\nIdentified {count} layers in the model. They are:\")\n",
        "for layer in video_swin.layers:\n",
        "  print(f\"{layer.name}\")\n",
        "\n",
        "print(f\"Video Swin Model Summary:\")\n",
        "video_swin.summary()\n",
        "\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-4,\n",
        "    decay_steps=100,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "\n",
        "drowsy_model = keras.Sequential([\n",
        "        video_swin,\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "drowsy_model.compile(\n",
        "    # optimizer=keras.optimizers.AdamW(\n",
        "    #   learning_rate=2e-5\n",
        "    #   #learning_rate=lr_schedule\n",
        "    # ), # from the ipynb, but we can definitely change optimizer later\n",
        "    optimizer=keras.optimizers.Nadam(learning_rate=0.001),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=keras.metrics.SparseCategoricalAccuracy()\n",
        ")"
      ],
      "metadata": {
        "id": "GkZyR6UIfV00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b073ba53-e483-47a4-e168-b1cbbc213df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFPatchEmbed3D set to trainable\n",
            "pos_drop set to trainable\n",
            "TFBasicLayer1 set to trainable\n",
            "TFBasicLayer2 set to trainable\n",
            "TFBasicLayer3 set to trainable\n",
            "TFBasicLayer4 set to trainable\n",
            "norm set to trainable\n",
            "adt_avg_pool3d set to trainable\n",
            "head set to trainable\n",
            "TFPatchEmbed3D\n",
            "pos_drop\n",
            "TFBasicLayer1\n",
            "TFBasicLayer2\n",
            "TFBasicLayer3\n",
            "TFBasicLayer4\n",
            "norm\n",
            "adt_avg_pool3d\n",
            "head\n",
            "Video Swin Model Summary:\n",
            "Model: \"TFVideoSwinB_SSV2_K400_P244_W1677_32x224\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " TFPatchEmbed3D (TFPatchEmb  multiple                  12672     \n",
            " ed3D)                                                           \n",
            "                                                                 \n",
            " pos_drop (Dropout)          multiple                  0         \n",
            "                                                                 \n",
            " TFBasicLayer1 (TFBasicLaye  multiple                  570552    \n",
            " r)                                                              \n",
            "                                                                 \n",
            " TFBasicLayer2 (TFBasicLaye  multiple                  2189680   \n",
            " r)                                                              \n",
            "                                                                 \n",
            " TFBasicLayer3 (TFBasicLaye  multiple                  60352992  \n",
            " r)                                                              \n",
            "                                                                 \n",
            " TFBasicLayer4 (TFBasicLaye  multiple                  25527744  \n",
            " r)                                                              \n",
            "                                                                 \n",
            " norm (LayerNormalization)   multiple                  2048      \n",
            "                                                                 \n",
            " adt_avg_pool3d (TFAdaptive  multiple                  0         \n",
            " AveragePooling3D)                                               \n",
            "                                                                 \n",
            " head (Dense)                multiple                  178350    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 88834038 (338.87 MB)\n",
            "Trainable params: 88834038 (338.87 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci4KA6rIthsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f12f8f7-7afa-455c-db39-a0ace08e1eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch image shape: (2, 32, 224, 224, 3)\n",
            "Batch labels: tf.Tensor([0 2], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "for images, labels in test_data.take(1):\n",
        "    print(\"Batch image shape:\", images.shape)  # Expected shape: (batch_size, 32, 112, 224, 3)\n",
        "    print(\"Batch labels:\", labels)\n",
        "\n",
        "# for images, labels in train_data.take(1):\n",
        "#     print(f\"images type: {type(images)}\")\n",
        "#     print(\"Batch image shape:\", images.shape)  # Expected shape: (batch_size, 32, 224, 224, 3)\n",
        "#     print(\"Batch labels:\", labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4lrvh30Zc-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7eb13c1-55db-4b64-dfe8-09b86b26442b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "106/106 [==============================] - 234s 1s/step - loss: 1.5993 - sparse_categorical_accuracy: 0.3302 - val_loss: 1.9885 - val_sparse_categorical_accuracy: 0.2830\n",
            "Epoch 2/20\n",
            "106/106 [==============================] - 124s 1s/step - loss: 1.6541 - sparse_categorical_accuracy: 0.2972 - val_loss: 1.5405 - val_sparse_categorical_accuracy: 0.3679\n",
            "Epoch 3/20\n",
            "106/106 [==============================] - 122s 1s/step - loss: 1.5214 - sparse_categorical_accuracy: 0.3255 - val_loss: 1.5523 - val_sparse_categorical_accuracy: 0.2925\n",
            "Epoch 4/20\n",
            "106/106 [==============================] - 121s 1s/step - loss: 1.4428 - sparse_categorical_accuracy: 0.3962 - val_loss: 1.1552 - val_sparse_categorical_accuracy: 0.3113\n",
            "Epoch 5/20\n",
            "106/106 [==============================] - 119s 1s/step - loss: 1.4020 - sparse_categorical_accuracy: 0.3160 - val_loss: 1.6344 - val_sparse_categorical_accuracy: 0.2075\n",
            "Epoch 6/20\n",
            "106/106 [==============================] - 115s 1s/step - loss: 1.3807 - sparse_categorical_accuracy: 0.3491 - val_loss: 1.2347 - val_sparse_categorical_accuracy: 0.3302\n",
            "Epoch 7/20\n",
            "106/106 [==============================] - 110s 1s/step - loss: 1.3510 - sparse_categorical_accuracy: 0.3679 - val_loss: 1.2464 - val_sparse_categorical_accuracy: 0.3019\n",
            "Epoch 8/20\n",
            "106/106 [==============================] - 106s 1s/step - loss: 1.2845 - sparse_categorical_accuracy: 0.3491 - val_loss: 1.0830 - val_sparse_categorical_accuracy: 0.3679\n",
            "Epoch 9/20\n",
            "106/106 [==============================] - 111s 1s/step - loss: 1.3395 - sparse_categorical_accuracy: 0.3019 - val_loss: 1.1060 - val_sparse_categorical_accuracy: 0.3396\n",
            "Epoch 10/20\n",
            "106/106 [==============================] - 106s 999ms/step - loss: 1.2546 - sparse_categorical_accuracy: 0.3208 - val_loss: 1.0917 - val_sparse_categorical_accuracy: 0.4151\n",
            "Epoch 11/20\n",
            "106/106 [==============================] - 107s 1s/step - loss: 1.2085 - sparse_categorical_accuracy: 0.3915 - val_loss: 1.1460 - val_sparse_categorical_accuracy: 0.3113\n",
            "Epoch 12/20\n",
            "106/106 [==============================] - 110s 1s/step - loss: 1.2592 - sparse_categorical_accuracy: 0.3538 - val_loss: 1.1494 - val_sparse_categorical_accuracy: 0.3019\n",
            "Epoch 13/20\n",
            "106/106 [==============================] - 109s 1s/step - loss: 1.2596 - sparse_categorical_accuracy: 0.2972 - val_loss: 1.1070 - val_sparse_categorical_accuracy: 0.3679\n",
            "Epoch 14/20\n",
            "106/106 [==============================] - 109s 1s/step - loss: 1.2201 - sparse_categorical_accuracy: 0.2830 - val_loss: 1.1144 - val_sparse_categorical_accuracy: 0.3019\n",
            "Epoch 15/20\n",
            "106/106 [==============================] - 107s 1s/step - loss: 1.2364 - sparse_categorical_accuracy: 0.3113 - val_loss: 1.0984 - val_sparse_categorical_accuracy: 0.3396\n",
            "Epoch 16/20\n",
            "106/106 [==============================] - 107s 1s/step - loss: 1.1238 - sparse_categorical_accuracy: 0.3585 - val_loss: 1.0959 - val_sparse_categorical_accuracy: 0.3774\n",
            "Epoch 17/20\n",
            "106/106 [==============================] - 108s 1s/step - loss: 1.1841 - sparse_categorical_accuracy: 0.3396 - val_loss: 1.0974 - val_sparse_categorical_accuracy: 0.3679\n",
            "Epoch 18/20\n",
            "106/106 [==============================] - 106s 1s/step - loss: 1.1344 - sparse_categorical_accuracy: 0.3302 - val_loss: 1.0935 - val_sparse_categorical_accuracy: 0.3774\n",
            "Epoch 19/20\n",
            "106/106 [==============================] - 109s 1s/step - loss: 1.1657 - sparse_categorical_accuracy: 0.3160 - val_loss: 1.1127 - val_sparse_categorical_accuracy: 0.3302\n",
            "Epoch 20/20\n",
            "106/106 [==============================] - 105s 994ms/step - loss: 1.1434 - sparse_categorical_accuracy: 0.2830 - val_loss: 1.0945 - val_sparse_categorical_accuracy: 0.3679\n"
          ]
        }
      ],
      "source": [
        "history = drowsy_model.fit(\n",
        "  train_data,\n",
        "  validation_data=test_data,\n",
        "  steps_per_epoch=106,#len(train_data) // batch_size,  analogous to window size? - tiff\n",
        "  validation_steps=validation_steps,\n",
        "  epochs=20, # change this\n",
        "  #callbacks=[early_stopping]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@article{liu2021video,\n",
        "  title={Video Swin Transformer},\n",
        "  author={Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},\n",
        "  journal={arXiv preprint arXiv:2106.13230},\n",
        "  year={2021}\n",
        "}"
      ],
      "metadata": {
        "id": "1_EaOMTugrEr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}