{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQNC_jZbWNq7"
      },
      "source": [
        "# Drowsiness Detection Final Project\n",
        "This colab contains the implementation of our final project, pulling our pre-processing and data augmentation code from Github, running our dataset through it, then applying another model, VideoSWIN, to produce the final results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCdY9y5zaI08"
      },
      "source": [
        "# Step 0: Project Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq1PJ7shXdh3"
      },
      "source": [
        "## Pulling the Github Repository\n",
        "To get Colab to access the Github repository, run the following code block:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8j0SHXuYejk",
        "outputId": "ffedd8da-ed16-448b-897e-3ad2fd28fdf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'deep-learning-final-project' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Call code to load the repository into Colab's runtime.\n",
        "# Todo: see how Ethan coded his pre-processing step to run\n",
        "# so that it can also work in colab\n",
        "!git clone https://github.com/EtomicBomb/deep-learning-final-project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U02HWfTNfyIy",
        "outputId": "3b7a5e4c-2148-4417-d0ef-0e7d2c309612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No local changes to save\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!cd /content/deep-learning-final-project; git stash; git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIWtUCBsYtFE"
      },
      "source": [
        "## Pulling in the data from Google Drive\n",
        "\n",
        "WARNING: before running below, you must make a shortcut of the shared folder that includes the data. Follow the steps below:\n",
        "\n",
        "1. Have the `deep-learning-final-project` folder shared with you.\n",
        "2. Right-click the folder and click `Organize` then `Add Shortcut`. when choosing where, click `All Locations` then choose your `Drive`.\n",
        "3. Make sure not to rename the shortcut!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdVqIXKkYxW6",
        "outputId": "561d3474-c7d6-47dd-f431-b2e9b3bd5ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Gf9ekbZN3G"
      },
      "source": [
        "## Running Data Preprocessing on Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSY-3-7WZUbT",
        "outputId": "8f625ec1-78de-49c7-d867-2c0becab1b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'VideoSwin' already exists and is not an empty directory.\n",
            "/content/VideoSwin\n",
            "Already on 'tfkeras'\n",
            "Your branch is up to date with 'origin/tfkeras'.\n",
            "Obtaining file:///content/VideoSwin\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from videoswin==1.0.0) (4.8.0.76)\n",
            "Requirement already satisfied: tensorflow>=2.12 in /usr/local/lib/python3.10/dist-packages (from videoswin==1.0.0) (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.2->videoswin==1.0.0) (1.25.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.12->videoswin==1.0.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.12->videoswin==1.0.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.12->videoswin==1.0.0) (3.2.2)\n",
            "Installing collected packages: videoswin\n",
            "  Attempting uninstall: videoswin\n",
            "    Found existing installation: videoswin 1.0.0\n",
            "    Uninstalling videoswin-1.0.0:\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.4.24)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (12.0.0)\n",
            "Requirement already satisfied: keras_cv in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_cv) (24.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_cv) (2023.12.25)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras_cv) (4.9.4)\n",
            "Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.1.7)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.1.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.5.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (6.4.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (4.11.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2024.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets->keras_cv) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# fulfill requirements\n",
        "# !pip install -r requirements.txt\n",
        "# !git clone https://github.com/innat/VideoSwin.git\n",
        "# # %cd VideoSwin\n",
        "# !git checkout tfkeras\n",
        "# !pip install -e  .\n",
        "# !pip install scikit-image\n",
        "# # dlib\n",
        "# !pip install numpy\n",
        "# !pip install matplotlib\n",
        "# !pip install av\n",
        "# !pip install keras_cv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qshlhlWtp5OE",
        "outputId": "48859b40-a38c-4fd5-d725-296622a0ab50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning-final-project/src\n"
          ]
        }
      ],
      "source": [
        "%cd /content/deep-learning-final-project/src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT1GdbGyv_0j",
        "outputId": "6aba4439-d0ef-4426-a6e5-0100c8eef436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n",
            "running Scale...\n",
            "running Gray2RGB...\n",
            "running Scale...\n",
            "running Gray2RGB...\n",
            "running Scale...\n",
            "running Gray2RGB...\n",
            "running Scale...\n",
            "running Gray2RGB...\n",
            "running Scale...\n",
            "running Gray2RGB...\n"
          ]
        }
      ],
      "source": [
        "from main import get_data\n",
        "import tensorflow as tf\n",
        "\n",
        "validation_steps = 20\n",
        "\n",
        "with tf.device('/CPU:0'):\n",
        "    train_data = get_data(\n",
        "        mode='train',\n",
        "        extract_root='/content/drive/MyDrive/deep-learning-final-project/data-2024-03-25/extract/',\n",
        "        data_root='/content/deep-learning-final-project/data',\n",
        "        batch_size=2,\n",
        "        frame_count=32,\n",
        "    )\n",
        "    test_data = get_data(\n",
        "        mode='test',\n",
        "        extract_root='/content/drive/MyDrive/deep-learning-final-project/data-2024-03-25/extract/',\n",
        "        data_root='/content/deep-learning-final-project/data',\n",
        "        batch_size=2,\n",
        "        frame_count=32,\n",
        "        validation_steps=validation_steps,\n",
        "    )\n",
        "\n",
        "# from main import train_test\n",
        "# import tensorflow as tf\n",
        "\n",
        "\n",
        "# with tf.device('/CPU:0'): # put the next thing on a new line\n",
        "#   train_data, test_data = train_test('/content/drive/MyDrive/deep-learning-final-project/data-2024-03-25/extract', '/content/deep-learning-final-project/data/split.json', validation_steps=validation_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZQQZWOSDYLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f809880d-f8b5-440e-c5d0-482647062ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(2, 32, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(2, 32, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "print(train_data)\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17s605yFY3qA"
      },
      "source": [
        "## Pulling in VideoSWIN model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpn6MApiZD85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e305ec3c-c5c4-4dcc-b550-9744047a8493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VideoSwin\n"
          ]
        }
      ],
      "source": [
        "# TODO: Check how VideoSWIN model checkpoint works\n",
        "# TODO: Check if VideoSWIN needs its repository pulled.\n",
        "# %cd /content/VideoSwin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjICPp0gBQh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d51c3fd-d2bc-442e-a09d-2ee80501260b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-06 03:56:01--  https://github.com/innat/VideoSwin/releases/download/v1.1/TFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/697696973/e6869381-0418-4489-bee3-99857237886b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240506%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240506T035602Z&X-Amz-Expires=300&X-Amz-Signature=277f72f53d693966da42337e7f35b683544d48ebf7d3a1e470c40c324baf943a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=697696973&response-content-disposition=attachment%3B%20filename%3DTFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-05-06 03:56:02--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/697696973/e6869381-0418-4489-bee3-99857237886b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240506%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240506T035602Z&X-Amz-Expires=300&X-Amz-Signature=277f72f53d693966da42337e7f35b683544d48ebf7d3a1e470c40c324baf943a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=697696973&response-content-disposition=attachment%3B%20filename%3DTFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 335787590 (320M) [application/octet-stream]\n",
            "Saving to: ‘TFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip’\n",
            "\n",
            "TFVideoSwinB_SSV2_K 100%[===================>] 320.23M   253MB/s    in 1.3s    \n",
            "\n",
            "2024-05-06 03:56:03 (253 MB/s) - ‘TFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip’ saved [335787590/335787590]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# this is the same import, but I (Patrick) do not know if there is another that is meant for tensorflow.keras specifically\n",
        "# !wget https://github.com/innat/VideoSwin/releases/download/v2.0/videoswin_base_something_something_v2.weights.h5 -q\n",
        "!wget 'https://github.com/innat/VideoSwin/releases/download/v1.1/TFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip'\n",
        "!unzip -q '/content/VideoSwin/TFVideoSwinB_SSV2_K400_P244_W1677_32x224.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42uHdUN4ZVVG"
      },
      "source": [
        "## Establish CNN between Data Preprocessing and *SWIN*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwwkXhJ1ZjMo"
      },
      "outputs": [],
      "source": [
        "# TODO - if needed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQddCOFbZj-U"
      },
      "source": [
        "## Establish Model Architecture + Loss Function, Call Function, Optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5IpQQkJZv_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f0b0842-1d33-4e69-d394-6fff1e505f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.8.0\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Conv2D, GlobalAveragePooling2D, MaxPooling2D\n",
        "import tensorflow.keras\n",
        "import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "!pip install einops\n",
        "\n",
        "# video_swin = load_model('/content/VideoSwin/videoswin_base_something_something_v2.weights.h5', compile=False)\n",
        "# video_swin = keras.layers.TFSMLayer(\n",
        "#     '/content/VideoSwin/TFVideoSwinB_SSV2_K400_P244_W1677_32x224',\n",
        "#     call_endpoint='serving_default',\n",
        "#     trainable=False,\n",
        "# )\n",
        "# policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "# tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# video_swin = load_model('/content/VideoSwin/TFVideoSwinB_SSV2_K400_P244_W1677_32x224', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HEIGHT = 224\n",
        "WIDTH = 224\n",
        "\n",
        "class Conv2Plus1D(keras.layers.Layer):\n",
        "  def __init__(self, filters, kernel_size, padding):\n",
        "    \"\"\"\n",
        "      A sequence of convolutional layers that first apply the convolution operation over the\n",
        "      spatial dimensions, and then the temporal dimension.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.seq = keras.Sequential([\n",
        "        # Spatial decomposition\n",
        "        layers.Conv3D(filters=filters,\n",
        "                      kernel_size=(1, kernel_size[1], kernel_size[2]),\n",
        "                      padding=padding),\n",
        "        # Temporal decomposition\n",
        "        layers.Conv3D(filters=filters,\n",
        "                      kernel_size=(kernel_size[0], 1, 1),\n",
        "                      padding=padding)\n",
        "        ])\n",
        "\n",
        "  def call(self, x):\n",
        "    return self.seq(x)"
      ],
      "metadata": {
        "id": "AbPbd7tVIE-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualMain(keras.layers.Layer):\n",
        "  \"\"\"\n",
        "    Residual block of the model with convolution, layer normalization, and the\n",
        "    activation function, ReLU.\n",
        "  \"\"\"\n",
        "  def __init__(self, filters, kernel_size):\n",
        "    super().__init__()\n",
        "    self.seq = keras.Sequential([\n",
        "        Conv2Plus1D(filters=filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    padding='same'),\n",
        "        layers.LayerNormalization(),\n",
        "        layers.ReLU(),\n",
        "        Conv2Plus1D(filters=filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    padding='same'),\n",
        "        layers.LayerNormalization()\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    return self.seq(x)\n",
        "\n",
        "class Project(keras.layers.Layer):\n",
        "  \"\"\"\n",
        "    Project certain dimensions of the tensor as the data is passed through different\n",
        "    sized filters and downsampled.\n",
        "  \"\"\"\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    self.seq = keras.Sequential([\n",
        "        layers.Dense(units),\n",
        "        layers.LayerNormalization()\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    return self.seq(x)\n",
        "\n",
        "\n",
        "def add_residual_block(input, filters, kernel_size):\n",
        "  \"\"\"\n",
        "    Add residual blocks to the model. If the last dimensions of the input data\n",
        "    and filter size does not match, project it such that last dimension matches.\n",
        "  \"\"\"\n",
        "  out = ResidualMain(filters,\n",
        "                     kernel_size)(input)\n",
        "\n",
        "  res = input\n",
        "  # Using the Keras functional APIs, project the last dimension of the tensor to\n",
        "  # match the new filter size\n",
        "  if out.shape[-1] != input.shape[-1]:\n",
        "    res = Project(out.shape[-1])(res)\n",
        "\n",
        "  return layers.add([res, out])"
      ],
      "metadata": {
        "id": "gXP34fFWITqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import rearrange, reduce, parse_shape\n",
        "class ResizeVideo(keras.layers.Layer):\n",
        "  def __init__(self, height, width):\n",
        "    super().__init__()\n",
        "    self.height = height\n",
        "    self.width = width\n",
        "    self.resizing_layer = layers.Resizing(self.height, self.width)\n",
        "\n",
        "  def call(self, video):\n",
        "    \"\"\"\n",
        "      Use the einops library to resize the tensor.\n",
        "\n",
        "      Args:\n",
        "        video: Tensor representation of the video, in the form of a set of frames.\n",
        "\n",
        "      Return:\n",
        "        A downsampled size of the video according to the new height and width it should be resized to.\n",
        "    \"\"\"\n",
        "    # b stands for batch size, t stands for time, h stands for height,\n",
        "    # w stands for width, and c stands for the number of channels.\n",
        "    old_shape = parse_shape(video, 'b t h w c')\n",
        "    images = rearrange(video, 'b t h w c -> (b t) h w c')\n",
        "    images = self.resizing_layer(images)\n",
        "    videos = rearrange(\n",
        "        images, '(b t) h w c -> b t h w c',\n",
        "        t = old_shape['t'])\n",
        "    return videos"
      ],
      "metadata": {
        "id": "J98ocfUsIjRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (2, 32, HEIGHT, WIDTH, 3)\n",
        "input = layers.Input(shape=(input_shape[1:]))\n",
        "x = input\n",
        "\n",
        "x = Conv2Plus1D(filters=16, kernel_size=(3, 7, 7), padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.ReLU()(x)\n",
        "x = ResizeVideo(HEIGHT // 2, WIDTH // 2)(x)\n",
        "\n",
        "# Block 1\n",
        "x = add_residual_block(x, 16, (3, 3, 3))\n",
        "x = ResizeVideo(HEIGHT // 4, WIDTH // 4)(x)\n",
        "\n",
        "# Block 2\n",
        "x = add_residual_block(x, 32, (3, 3, 3))\n",
        "x = ResizeVideo(HEIGHT // 8, WIDTH // 8)(x)\n",
        "\n",
        "# Block 3\n",
        "x = add_residual_block(x, 64, (3, 3, 3))\n",
        "x = ResizeVideo(HEIGHT // 16, WIDTH // 16)(x)\n",
        "\n",
        "# Block 4\n",
        "x = add_residual_block(x, 128, (3, 3, 3))\n",
        "\n",
        "x = layers.GlobalAveragePooling3D()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(3)(x)\n",
        "\n",
        "drowsy_model = keras.Model(input, x)\n",
        "frames, label = next(iter(train_data))\n",
        "drowsy_model.build(frames)"
      ],
      "metadata": {
        "id": "HbYVd0lxIovz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drowsy_model.compile(\n",
        "#     optimizer=keras.optimizers.AdamW(\n",
        "#       learning_rate=1e-5\n",
        "#     ), # from the ipynb, but we can definitely change optimizer later\n",
        "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#     metrics=keras.metrics.SparseCategoricalAccuracy()\n",
        "# )\n",
        "\n",
        "\n",
        "drowsy_model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer = keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "bEeeVbteKh-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci4KA6rIthsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59684c81-2d86-46df-fcef-fe3b1567250b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch image shape: (2, 32, 224, 224, 3)\n",
            "Batch labels: tf.Tensor([2 1], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "for images, labels in test_data.take(1):\n",
        "    print(\"Batch image shape:\", images.shape)  # Expected shape: (batch_size, 32, 112, 224, 3)\n",
        "    print(\"Batch labels:\", labels)\n",
        "\n",
        "# for images, labels in train_data.take(1):\n",
        "#     print(f\"images type: {type(images)}\")\n",
        "#     print(\"Batch image shape:\", images.shape)  # Expected shape: (batch_size, 32, 224, 224, 3)\n",
        "#     print(\"Batch labels:\", labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4lrvh30Zc-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3fba2ae-475b-42df-9472-8d04beb6ad04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 41s 3s/step - loss: 1.2792 - accuracy: 0.5500 - val_loss: 1.9165 - val_accuracy: 0.4500\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 24s 3s/step - loss: 1.4709 - accuracy: 0.5500 - val_loss: 2.4058 - val_accuracy: 0.2750\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.1971 - accuracy: 0.4500"
          ]
        }
      ],
      "source": [
        "history = drowsy_model.fit(\n",
        "  train_data,\n",
        "  validation_data=test_data,\n",
        "  steps_per_epoch=10,#len(train_data) // batch_size,  analogous to window size? - tiff\n",
        "  validation_steps=validation_steps,\n",
        "  epochs=10, # change this\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WLO62r2A4cr"
      },
      "source": [
        "## Results\n",
        "With 2 layers de-frozen & 1 epoch, we get the following results:\n",
        "loss: 2.8143 - sparse_categorical_accuracy: 0.2500\n",
        "With 3 layers de-frosted & 1 epoch:\n",
        "loss: 2.8143 - sparse_categorical_accuracy: 0.2500 - val_loss: 1.3212 - val_sparse_categorical_accuracy: 0.4500\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}